Traceback (most recent call last):
  File "C:\Users\bais_\source\repos\Progetto\NLP-customer-classification\src\utils\utils.py", line 71, in train_and_log
    model, tokenizer = load_BERT_encoder(config.model_name)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bais_\source\repos\Progetto\NLP-customer-classification\src\utils\utils.py", line 130, in load_BERT_encoder
    model = model.to('cuda')
            ^^^^^^^^^^^^^^^^
  File "C:\Users\bais_\anaconda3\Lib\site-packages\transformers\modeling_utils.py", line 2952, in to
    return super().to(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bais_\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1174, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bais_\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 780, in _apply
    module._apply(fn)
  File "C:\Users\bais_\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 780, in _apply
    module._apply(fn)
  File "C:\Users\bais_\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 805, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "C:\Users\bais_\anaconda3\Lib\site-packages\torch\nn\modules\module.py", line 1160, in convert
    return t.to(
           ^^^^^
RuntimeError: CUDA error: the launch timed out and was terminated
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.